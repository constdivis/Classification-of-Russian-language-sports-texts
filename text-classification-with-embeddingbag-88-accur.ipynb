{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/constantinedivis/text-classification-with-embeddingbag-88-accur?scriptVersionId=142888161\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"# Data loading","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd","metadata":{"execution":{"iopub.status.busy":"2023-09-13T14:11:01.628846Z","iopub.execute_input":"2023-09-13T14:11:01.629255Z","iopub.status.idle":"2023-09-13T14:11:01.989851Z","shell.execute_reply.started":"2023-09-13T14:11:01.629219Z","shell.execute_reply":"2023-09-13T14:11:01.9889Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/russian-social-media-text-classification/train.csv')\ntest = pd.read_csv('/kaggle/input/russian-social-media-text-classification/test.csv')\nsample_submission = pd.read_csv('/kaggle/input/russian-social-media-text-classification/sample_submission.csv')\nCLASSES = list(train['category'].unique())\nCLASSES","metadata":{"execution":{"iopub.status.busy":"2023-09-13T14:11:01.991892Z","iopub.execute_input":"2023-09-13T14:11:01.992375Z","iopub.status.idle":"2023-09-13T14:11:02.901948Z","shell.execute_reply.started":"2023-09-13T14:11:01.992341Z","shell.execute_reply":"2023-09-13T14:11:02.900886Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.head()","metadata":{"execution":{"iopub.status.busy":"2023-09-13T14:11:02.903667Z","iopub.execute_input":"2023-09-13T14:11:02.904042Z","iopub.status.idle":"2023-09-13T14:11:02.916908Z","shell.execute_reply.started":"2023-09-13T14:11:02.904009Z","shell.execute_reply":"2023-09-13T14:11:02.91578Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Drop duplicates","metadata":{}},{"cell_type":"code","source":"len(train)","metadata":{"execution":{"iopub.status.busy":"2023-09-13T14:11:02.920702Z","iopub.execute_input":"2023-09-13T14:11:02.921041Z","iopub.status.idle":"2023-09-13T14:11:02.928481Z","shell.execute_reply.started":"2023-09-13T14:11:02.92101Z","shell.execute_reply":"2023-09-13T14:11:02.927406Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(train.text.unique())","metadata":{"execution":{"iopub.status.busy":"2023-09-13T14:11:02.930145Z","iopub.execute_input":"2023-09-13T14:11:02.930584Z","iopub.status.idle":"2023-09-13T14:11:03.085084Z","shell.execute_reply.started":"2023-09-13T14:11:02.930548Z","shell.execute_reply":"2023-09-13T14:11:03.084066Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.drop_duplicates(subset=['text'], inplace=True)","metadata":{"execution":{"iopub.status.busy":"2023-09-13T14:11:03.086322Z","iopub.execute_input":"2023-09-13T14:11:03.087426Z","iopub.status.idle":"2023-09-13T14:11:03.117597Z","shell.execute_reply.started":"2023-09-13T14:11:03.08739Z","shell.execute_reply":"2023-09-13T14:11:03.116631Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data splitting","metadata":{}},{"cell_type":"code","source":"df_train, df_val, df_test = np.split(train.sample(frac=1, random_state=42),\n                                     [int(.85*len(train)), int(.95*len(train))])\n\ndic_train = df_train.to_dict('index')\ndic_val = df_val.to_dict('index')\ndic_test = df_test.to_dict('index')\n","metadata":{"execution":{"iopub.status.busy":"2023-09-13T14:11:03.119035Z","iopub.execute_input":"2023-09-13T14:11:03.119482Z","iopub.status.idle":"2023-09-13T14:11:03.285691Z","shell.execute_reply.started":"2023-09-13T14:11:03.119447Z","shell.execute_reply":"2023-09-13T14:11:03.28464Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data preprocessing","metadata":{}},{"cell_type":"code","source":"import nltk\nfrom nltk.tokenize import RegexpTokenizer\n\nnltk.download('stopwords')\nfrom nltk.corpus import stopwords\n\nimport string\nimport re\n\n!pip install pymorphy2\nimport pymorphy2","metadata":{"execution":{"iopub.status.busy":"2023-09-13T14:11:03.287228Z","iopub.execute_input":"2023-09-13T14:11:03.287576Z","iopub.status.idle":"2023-09-13T14:11:15.925388Z","shell.execute_reply.started":"2023-09-13T14:11:03.287543Z","shell.execute_reply":"2023-09-13T14:11:15.924082Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizer = RegexpTokenizer(r'\\w+')\nmorph = pymorphy2.MorphAnalyzer()\n\nstop = set(stopwords.words('russian'))\nstop.add('это')\nstop.remove('я')\n\nexclude = set(string.punctuation)\n\ntok_for_del = list(stop) + list(exclude)","metadata":{"execution":{"iopub.status.busy":"2023-09-13T14:11:15.929472Z","iopub.execute_input":"2023-09-13T14:11:15.929818Z","iopub.status.idle":"2023-09-13T14:11:16.144285Z","shell.execute_reply.started":"2023-09-13T14:11:15.929777Z","shell.execute_reply":"2023-09-13T14:11:16.143082Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Lemmatisation","metadata":{}},{"cell_type":"code","source":"def str_lemm(str):\n    \n    \"\"\"\n    string lemmatisation\n    \"\"\"\n\n    raw = str.lower()\n\n    tokens = tokenizer.tokenize(raw)\n\n    tokens_clean_wo_stop = [j for j in tokens if not j in tok_for_del]\n\n    tokens_clean = [re.sub('^\\d*\\n*|\\n*\\d*$', '', j) for j in tokens_clean_wo_stop]\n\n    tokens_clean = [j for j in tokens_clean if len(j) > 1]\n\n    lemms_p_of_s = [(morph.parse(j)[0]) for j in tokens_clean if j != '']\n    lemms = [j[2] for j in lemms_p_of_s]\n\n    return lemms","metadata":{"execution":{"iopub.status.busy":"2023-09-13T14:11:16.150243Z","iopub.execute_input":"2023-09-13T14:11:16.150563Z","iopub.status.idle":"2023-09-13T14:11:16.15819Z","shell.execute_reply.started":"2023-09-13T14:11:16.150536Z","shell.execute_reply":"2023-09-13T14:11:16.157083Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def sample_lemm(data):\n    \"\"\"\n    sample lemmatisation\n    \"\"\"\n    dct = dict()\n\n    for k in data:\n        dct[k] = (data[k]['category'], str_lemm(data[k]['text']))\n\n    return dct","metadata":{"execution":{"iopub.status.busy":"2023-09-13T14:11:16.159597Z","iopub.execute_input":"2023-09-13T14:11:16.159898Z","iopub.status.idle":"2023-09-13T14:11:16.174944Z","shell.execute_reply.started":"2023-09-13T14:11:16.159871Z","shell.execute_reply":"2023-09-13T14:11:16.173933Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dic_train_texts_lemm = sample_lemm(dic_train)\ndic_val_texts_lemm = sample_lemm(dic_val)\ndic_test_texts_lemm = sample_lemm(dic_test)","metadata":{"execution":{"iopub.status.busy":"2023-09-13T14:11:16.176539Z","iopub.execute_input":"2023-09-13T14:11:16.176941Z","iopub.status.idle":"2023-09-13T14:17:26.413371Z","shell.execute_reply.started":"2023-09-13T14:11:16.176906Z","shell.execute_reply":"2023-09-13T14:17:26.412334Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def dic2lst(dct):\n    \"\"\"\n    dict to lists\n   \n    \"\"\"\n    texts = []\n    categories = []\n\n    for k in dct:\n        texts.append(dct[k][1])\n        categories.append(dct[k][0])\n\n    return texts, categories","metadata":{"execution":{"iopub.status.busy":"2023-09-13T14:17:26.414738Z","iopub.execute_input":"2023-09-13T14:17:26.415121Z","iopub.status.idle":"2023-09-13T14:17:26.421124Z","shell.execute_reply.started":"2023-09-13T14:17:26.415072Z","shell.execute_reply":"2023-09-13T14:17:26.420101Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_texts_text, train_texts_cat = dic2lst(dic_train_texts_lemm)\nval_texts_text, val_texts_cat = dic2lst(dic_val_texts_lemm)\ntest_texts_text, test_texts_cat = dic2lst(dic_test_texts_lemm)","metadata":{"execution":{"iopub.status.busy":"2023-09-13T14:17:26.422545Z","iopub.execute_input":"2023-09-13T14:17:26.423193Z","iopub.status.idle":"2023-09-13T14:17:26.452177Z","shell.execute_reply.started":"2023-09-13T14:17:26.423161Z","shell.execute_reply":"2023-09-13T14:17:26.451295Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Classification with EmbeddingBag - PyTorch","metadata":{}},{"cell_type":"code","source":"import torch\n\nfrom torchtext.data.utils import get_tokenizer\nfrom torchtext.vocab import build_vocab_from_iterator\n\nfrom sklearn import preprocessing\n\nfrom torch import nn\n\nfrom torch.utils.data import DataLoader\nfrom torch.utils.data.dataset import random_split\nfrom torchtext.data.functional import to_map_style_dataset\n\n!pip install torcheval\nfrom torcheval.metrics.functional import multiclass_f1_score\n\nimport time","metadata":{"execution":{"iopub.status.busy":"2023-09-13T14:19:37.873807Z","iopub.execute_input":"2023-09-13T14:19:37.874239Z","iopub.status.idle":"2023-09-13T14:19:49.787002Z","shell.execute_reply.started":"2023-09-13T14:19:37.874204Z","shell.execute_reply":"2023-09-13T14:19:49.785633Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data preparation","metadata":{}},{"cell_type":"code","source":"# tokens to strings\ntrain_texts = [' '.join(i) for i in train_texts_text]\ntest_texts = [' '.join(i) for i in test_texts_text]\nval_texts = [' '.join(i) for i in val_texts_text]","metadata":{"execution":{"iopub.status.busy":"2023-09-13T14:17:40.812185Z","iopub.execute_input":"2023-09-13T14:17:40.812833Z","iopub.status.idle":"2023-09-13T14:17:40.918258Z","shell.execute_reply.started":"2023-09-13T14:17:40.812794Z","shell.execute_reply":"2023-09-13T14:17:40.917075Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# label encoding\nle = preprocessing.LabelEncoder()\nle.fit(train_texts_cat)\nle.classes_","metadata":{"execution":{"iopub.status.busy":"2023-09-13T14:17:40.919849Z","iopub.execute_input":"2023-09-13T14:17:40.92022Z","iopub.status.idle":"2023-09-13T14:17:40.946265Z","shell.execute_reply.started":"2023-09-13T14:17:40.920176Z","shell.execute_reply":"2023-09-13T14:17:40.94534Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_lbl = le.transform(train_texts_cat)\ntest_lbl = le.transform(test_texts_cat)\nval_lbl = le.transform(val_texts_cat)","metadata":{"execution":{"iopub.status.busy":"2023-09-13T14:17:40.947465Z","iopub.execute_input":"2023-09-13T14:17:40.947817Z","iopub.status.idle":"2023-09-13T14:17:40.986244Z","shell.execute_reply.started":"2023-09-13T14:17:40.947785Z","shell.execute_reply":"2023-09-13T14:17:40.985375Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def torch_data_prepar(X, y):\n\n    \"\"\"\n    iterator for data\n    \"\"\"\n    out = []\n\n    for i in range(0, len(X)):\n        out.append((y[i], X[i]))\n\n    return iter(out)","metadata":{"execution":{"iopub.status.busy":"2023-09-13T14:17:40.9876Z","iopub.execute_input":"2023-09-13T14:17:40.98793Z","iopub.status.idle":"2023-09-13T14:17:40.99424Z","shell.execute_reply.started":"2023-09-13T14:17:40.987899Z","shell.execute_reply":"2023-09-13T14:17:40.993082Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_iter = torch_data_prepar(X = train_texts, y = train_lbl)\n\nvocab = build_vocab_from_iterator(i.split() for i in train_texts)\n\nwords = set(vocab.get_itos())\n\ntest_texts_ed = [[i for i in l.split() if i in words] for l in test_texts]\n\nval_texts_ed = [[i for i in l.split() if i in words] for l in val_texts]\n\nval_iter = torch_data_prepar(X = [\" \".join(i) for i in val_texts_ed], y = val_lbl)\ntest_iter = torch_data_prepar(X = [\" \".join(i) for i in test_texts_ed], y = test_lbl)\n\ntext_pipeline = lambda x: vocab([i for i in x.split()])\nlabel_pipeline = lambda x: int(x)","metadata":{"execution":{"iopub.status.busy":"2023-09-13T14:17:40.995486Z","iopub.execute_input":"2023-09-13T14:17:40.996459Z","iopub.status.idle":"2023-09-13T14:17:41.713884Z","shell.execute_reply.started":"2023-09-13T14:17:40.996426Z","shell.execute_reply":"2023-09-13T14:17:41.71288Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(vocab.get_itos())","metadata":{"execution":{"iopub.status.busy":"2023-09-13T14:17:41.715252Z","iopub.execute_input":"2023-09-13T14:17:41.715609Z","iopub.status.idle":"2023-09-13T14:17:41.743475Z","shell.execute_reply.started":"2023-09-13T14:17:41.715577Z","shell.execute_reply":"2023-09-13T14:17:41.742499Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"text_pipeline(\"хоккей просто\")","metadata":{"execution":{"iopub.status.busy":"2023-09-13T14:17:41.746378Z","iopub.execute_input":"2023-09-13T14:17:41.746702Z","iopub.status.idle":"2023-09-13T14:17:41.754069Z","shell.execute_reply.started":"2023-09-13T14:17:41.746677Z","shell.execute_reply":"2023-09-13T14:17:41.75294Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model","metadata":{}},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\ndef collate_batch(batch):\n    label_list, text_list, offsets = [], [], [0]\n    for (_label, _text) in batch:\n         label_list.append(label_pipeline(_label))\n         processed_text = torch.tensor(text_pipeline(_text), dtype=torch.int64)\n         text_list.append(processed_text)\n         offsets.append(processed_text.size(0))\n    label_list = torch.tensor(label_list, dtype=torch.int64)\n    offsets = torch.tensor(offsets[:-1]).cumsum(dim=0)\n    text_list = torch.cat(text_list)\n    return label_list.to(device), text_list.to(device), offsets.to(device)","metadata":{"execution":{"iopub.status.busy":"2023-09-13T14:17:41.755826Z","iopub.execute_input":"2023-09-13T14:17:41.756392Z","iopub.status.idle":"2023-09-13T14:17:41.831304Z","shell.execute_reply.started":"2023-09-13T14:17:41.756352Z","shell.execute_reply":"2023-09-13T14:17:41.830248Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class TextClassificationModel(nn.Module):\n\n    def __init__(self, vocab_size, embed_dim, num_class):\n        super(TextClassificationModel, self).__init__()\n        self.embedding = nn.EmbeddingBag(vocab_size, embed_dim, sparse=False)\n        self.fc = nn.Linear(embed_dim, embed_dim)\n        self.dropout = nn.Dropout(0.5)\n        self.fc = nn.Linear(embed_dim, num_class)\n#         self.dropout = nn.Dropout(0.3)\n        self.init_weights()\n\n    def init_weights(self):\n        initrange = 0.5\n        self.embedding.weight.data.uniform_(-initrange, initrange)\n        self.fc.weight.data.uniform_(-initrange, initrange)\n        self.fc.bias.data.zero_()\n\n    def forward(self, text, offsets):\n        embedded = self.embedding(text, offsets)\n        return self.fc(embedded)","metadata":{"execution":{"iopub.status.busy":"2023-09-13T14:17:41.832593Z","iopub.execute_input":"2023-09-13T14:17:41.83296Z","iopub.status.idle":"2023-09-13T14:17:41.846483Z","shell.execute_reply.started":"2023-09-13T14:17:41.832923Z","shell.execute_reply":"2023-09-13T14:17:41.84545Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train(dataloader):\n    model.train()\n    total_acc, total_count = 0, 0\n    log_interval = 500\n    start_time = time.time()\n\n    for idx, (label, text, offsets) in enumerate(dataloader):\n        optimizer.zero_grad()\n        predicted_label = model(text, offsets)\n        loss = criterion(predicted_label, label)\n        loss.backward()\n        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.1)\n        optimizer.step()\n        total_acc += (predicted_label.argmax(1) == label).sum().item()\n        total_count += label.size(0)\n        if idx % log_interval == 0 and idx > 0:\n            elapsed = time.time() - start_time\n            print('| epoch {:3d} | {:5d}/{:5d} batches '\n                  '| accuracy {:8.3f}'.format(epoch, idx, len(dataloader),\n                                              total_acc/total_count))\n            total_acc, total_count = 0, 0\n            start_time = time.time()","metadata":{"execution":{"iopub.status.busy":"2023-09-13T14:17:41.84948Z","iopub.execute_input":"2023-09-13T14:17:41.849745Z","iopub.status.idle":"2023-09-13T14:17:41.87402Z","shell.execute_reply.started":"2023-09-13T14:17:41.849722Z","shell.execute_reply":"2023-09-13T14:17:41.873067Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def evaluate(dataloader):\n    model.eval()\n    total_acc, total_count = 0, 0\n\n    with torch.no_grad():\n        for idx, (label, text, offsets) in enumerate(dataloader):\n            predicted_label = model(text, offsets)\n            loss = criterion(predicted_label, label)\n            total_acc += (predicted_label.argmax(1) == label).sum().item()\n            total_count += label.size(0)\n    return total_acc/total_count","metadata":{"execution":{"iopub.status.busy":"2023-09-13T14:17:41.875533Z","iopub.execute_input":"2023-09-13T14:17:41.876047Z","iopub.status.idle":"2023-09-13T14:17:41.889347Z","shell.execute_reply.started":"2023-09-13T14:17:41.876016Z","shell.execute_reply":"2023-09-13T14:17:41.888393Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_class = len(set([i for i in train_lbl]))\nvocab_size = len(vocab)\nemsize = 64\nmodel = TextClassificationModel(vocab_size, emsize, num_class).to(device)\n\nEPOCHS = 6\nLR = 0.001\nBATCH_SIZE = 32\n\ncriterion = torch.nn.CrossEntropyLoss()\noptimizer = torch.optim.AdamW(model.parameters(), lr=LR)\nscheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.1)\ntotal_accu = None","metadata":{"execution":{"iopub.status.busy":"2023-09-13T14:17:41.890665Z","iopub.execute_input":"2023-09-13T14:17:41.891285Z","iopub.status.idle":"2023-09-13T14:17:43.544581Z","shell.execute_reply.started":"2023-09-13T14:17:41.891253Z","shell.execute_reply":"2023-09-13T14:17:43.543539Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataset = to_map_style_dataset(train_iter)\ntest_dataset = to_map_style_dataset(test_iter)\nval_dataset = to_map_style_dataset(val_iter)\n\n\ntrain_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE,\n                              shuffle=True, collate_fn=collate_batch)\nvalid_dataloader = DataLoader(val_dataset, batch_size=BATCH_SIZE,\n                              shuffle=True, collate_fn=collate_batch)\ntest_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE,\n                             shuffle=True, collate_fn=collate_batch)","metadata":{"execution":{"iopub.status.busy":"2023-09-13T14:17:43.549881Z","iopub.execute_input":"2023-09-13T14:17:43.550197Z","iopub.status.idle":"2023-09-13T14:17:43.56317Z","shell.execute_reply.started":"2023-09-13T14:17:43.550169Z","shell.execute_reply":"2023-09-13T14:17:43.562133Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for epoch in range(1, EPOCHS + 1):\n    epoch_start_time = time.time()\n    train(train_dataloader)\n    accu_val = evaluate(valid_dataloader)\n    if total_accu is not None and total_accu > accu_val:\n          scheduler.step()\n    else:\n           total_accu = accu_val\n    print('-' * 59)\n    print('| end of epoch {:3d} | time: {:5.2f}s | '\n          'valid accuracy {:8.3f} '.format(epoch,\n                                           time.time() - epoch_start_time,\n                                           accu_val))\n\n    print('-' * 59)","metadata":{"execution":{"iopub.status.busy":"2023-09-13T14:19:49.789791Z","iopub.execute_input":"2023-09-13T14:19:49.79022Z","iopub.status.idle":"2023-09-13T14:20:16.241307Z","shell.execute_reply.started":"2023-09-13T14:19:49.790169Z","shell.execute_reply":"2023-09-13T14:20:16.239466Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Checking the results of test dataset.')\naccu_test = evaluate(test_dataloader)\nprint('test accuracy {:5.2f}'.format(accu_test))","metadata":{"execution":{"iopub.status.busy":"2023-09-13T14:20:20.676754Z","iopub.execute_input":"2023-09-13T14:20:20.677152Z","iopub.status.idle":"2023-09-13T14:20:20.778323Z","shell.execute_reply.started":"2023-09-13T14:20:20.677114Z","shell.execute_reply":"2023-09-13T14:20:20.777176Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## $F1$","metadata":{}},{"cell_type":"code","source":"test_dataloader2 = DataLoader(test_dataset, shuffle=True, collate_fn=collate_batch)\n\nmodel.eval()\n\npredicted_label_all = []\ntrue_lbls = []\n\nwith torch.no_grad():\n\n    for idx, (label, text, offsets) in enumerate(test_dataloader2):\n        predicted_label = model(text, offsets)\n        true_lbls.append(label[0])\n        predicted_label_all.append(predicted_label)\n\ny_pred = [j.argmax() for i in predicted_label_all for j in i]\n\nf1_score = multiclass_f1_score(torch.stack(y_pred), \n                               torch.stack(true_lbls), \n                               num_classes=13)\n\nprint(f'F1 = {f1_score:.3f}')","metadata":{"execution":{"iopub.status.busy":"2023-09-13T14:20:25.375577Z","iopub.execute_input":"2023-09-13T14:20:25.375956Z","iopub.status.idle":"2023-09-13T14:20:26.046967Z","shell.execute_reply.started":"2023-09-13T14:20:25.375925Z","shell.execute_reply":"2023-09-13T14:20:26.045902Z"},"trusted":true},"execution_count":null,"outputs":[]}],"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}}